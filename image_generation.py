#!/usr/bin/env python3
"""
Ejemplo de Generaci√≥n de Im√°genes con Hugging Face
==================================================

Este script demuestra c√≥mo usar modelos de diffusion para generar im√°genes
a partir de prompts de texto usando Stable Diffusion.
"""

import os
import torch
import warnings
from datetime import datetime
from PIL import Image
import matplotlib.pyplot as plt

# Suprimir warnings de xformers
warnings.filterwarnings("ignore", category=UserWarning, module="xformers")
os.environ["XFORMERS_MORE_DETAILS"] = "0"

try:
    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
except ImportError as e:
    print(f"‚ùå Error importando diffusers: {e}")
    print("üí° Solucionando problema de dependencias...")
    
    # Desinstalar xformers problem√°tico
    import subprocess
    import sys
    
    try:
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "xformers", "-y"], 
                      capture_output=True, check=False)
        print("‚úÖ xformers desinstalado")
    except:
        pass
    
    # Intentar importar de nuevo
    try:
        from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
        print("‚úÖ Diffusers importado exitosamente")
    except ImportError as e2:
        print(f"‚ùå Error persistente: {e2}")
        print("üí° Instalando versi√≥n compatible...")
        subprocess.run([sys.executable, "-m", "pip", "install", "diffusers==0.21.4"], 
                      capture_output=True)
        from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

def crear_directorio_salida():
    """
    Crea el directorio para guardar las im√°genes generadas
    """
    directorio = "imagenes_generadas"
    if not os.path.exists(directorio):
        os.makedirs(directorio)
        print(f"üìÅ Directorio creado: {directorio}")
    return directorio

def generar_imagen_basica():
    """
    Genera im√°genes usando Stable Diffusion con prompts b√°sicos
    """
    print("üé® Generaci√≥n B√°sica de Im√°genes...")
    print("=" * 60)
    
    # Configurar el dispositivo
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üñ•Ô∏è  Dispositivo: {device}")
    
    # Cargar el modelo Stable Diffusion
    print("üì• Cargando modelo Stable Diffusion...")
    model_id = "runwayml/stable-diffusion-v1-5"
    
    try:
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        pipe = pipe.to(device)
        
        # Optimizar para velocidad
        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
        
        # Habilitar optimizaciones de memoria si es necesario
        if device == "cpu":
            pipe.enable_attention_slicing()
        
        print("‚úÖ Modelo cargado exitosamente!")
        
    except Exception as e:
        print(f"‚ùå Error cargando el modelo: {e}")
        print("üí° Intentando con modelo alternativo m√°s ligero...")
        
        # Modelo alternativo m√°s peque√±o
        model_id = "CompVis/stable-diffusion-v1-4"
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        pipe = pipe.to(device)
        pipe.enable_attention_slicing()
    
    # Crear directorio de salida
    directorio_salida = crear_directorio_salida()
    
    # Prompts de ejemplo en espa√±ol e ingl√©s
    prompts_ejemplo = [
        {
            "prompt": "a beautiful sunset over a mountain landscape, digital art, highly detailed",
            "nombre": "atardecer_montanas"
        },
        {
            "prompt": "a cute robot reading a book in a cozy library, cartoon style, warm lighting",
            "nombre": "robot_biblioteca"
        },
        {
            "prompt": "a magical forest with glowing mushrooms and fairy lights, fantasy art",
            "nombre": "bosque_magico"
        },
        {
            "prompt": "a steampunk airship flying through clouds, vintage style, detailed",
            "nombre": "dirigible_steampunk"
        },
        {
            "prompt": "a cyberpunk cityscape at night with neon lights, futuristic, high contrast",
            "nombre": "ciudad_cyberpunk"
        }
    ]
    
    print(f"\nüñºÔ∏è  Generando {len(prompts_ejemplo)} im√°genes...")
    print("-" * 60)
    
    imagenes_generadas = []
    
    for i, ejemplo in enumerate(prompts_ejemplo, 1):
        prompt = ejemplo["prompt"]
        nombre_archivo = ejemplo["nombre"]
        
        print(f"\n{i}. Generando: {prompt[:50]}...")
        
        try:
            # Generar imagen
            with torch.autocast(device):
                imagen = pipe(
                    prompt,
                    num_inference_steps=20,  # Menos pasos para velocidad
                    guidance_scale=7.5,
                    width=512,
                    height=512
                ).images[0]
            
            # Guardar imagen
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            ruta_archivo = os.path.join(directorio_salida, f"{nombre_archivo}_{timestamp}.png")
            imagen.save(ruta_archivo)
            
            imagenes_generadas.append({
                "imagen": imagen,
                "prompt": prompt,
                "archivo": ruta_archivo
            })
            
            print(f"   ‚úÖ Guardada como: {ruta_archivo}")
            
        except Exception as e:
            print(f"   ‚ùå Error generando imagen: {e}")
            continue
    
    return imagenes_generadas

def generar_imagen_personalizada():
    """
    Permite al usuario ingresar sus propios prompts
    """
    print("\nüé≠ Generaci√≥n Personalizada de Im√°genes...")
    print("=" * 60)
    
    # Configurar el dispositivo
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Cargar modelo (reutilizar si ya est√° cargado)
    print("üì• Cargando modelo...")
    model_id = "runwayml/stable-diffusion-v1-5"
    
    try:
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        pipe = pipe.to(device)
        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
        
        if device == "cpu":
            pipe.enable_attention_slicing()
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None
    
    directorio_salida = crear_directorio_salida()
    
    print("\nüí° Consejos para mejores prompts:")
    print("   ‚Ä¢ S√© espec√≠fico: 'gato naranja durmiendo en un sof√° azul'")
    print("   ‚Ä¢ A√±ade estilo: 'digital art', 'oil painting', 'cartoon style'")
    print("   ‚Ä¢ Incluye detalles: 'highly detailed', 'beautiful lighting'")
    print("   ‚Ä¢ Usa ingl√©s para mejores resultados")
    print("\nüìù Escribe 'salir' para terminar")
    
    contador = 1
    while True:
        print(f"\nüé® Imagen #{contador}")
        prompt_usuario = input("Ingresa tu prompt: ").strip()
        
        if prompt_usuario.lower() in ['salir', 'exit', 'quit']:
            print("üëã ¬°Hasta luego!")
            break
        
        if not prompt_usuario:
            print("‚ö†Ô∏è  Por favor ingresa un prompt v√°lido")
            continue
        
        print(f"üîÑ Generando imagen para: '{prompt_usuario}'...")
        
        try:
            # Par√°metros personalizables
            print("‚öôÔ∏è  Configuraci√≥n (presiona Enter para usar valores por defecto):")
            
            # Pasos de inferencia
            pasos_input = input("   Pasos de inferencia (20): ").strip()
            pasos = int(pasos_input) if pasos_input.isdigit() else 20
            
            # Guidance scale
            guidance_input = input("   Guidance scale (7.5): ").strip()
            guidance = float(guidance_input) if guidance_input else 7.5
            
            # Dimensiones
            width_input = input("   Ancho (512): ").strip()
            width = int(width_input) if width_input.isdigit() else 512
            
            height_input = input("   Alto (512): ").strip()
            height = int(height_input) if height_input.isdigit() else 512
            
            # Generar imagen
            with torch.autocast(device):
                imagen = pipe(
                    prompt_usuario,
                    num_inference_steps=pasos,
                    guidance_scale=guidance,
                    width=width,
                    height=height
                ).images[0]
            
            # Guardar imagen
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            nombre_archivo = f"custom_{contador}_{timestamp}.png"
            ruta_archivo = os.path.join(directorio_salida, nombre_archivo)
            imagen.save(ruta_archivo)
            
            print(f"‚úÖ Imagen guardada como: {ruta_archivo}")
            
            # Mostrar imagen (opcional)
            mostrar = input("¬øMostrar imagen? (s/n): ").lower()
            if mostrar in ['s', 'si', 's√≠', 'y', 'yes']:
                try:
                    imagen.show()
                except Exception:
                    print("‚ö†Ô∏è  No se pudo mostrar la imagen autom√°ticamente")
            
            contador += 1
            
        except Exception as e:
            print(f"‚ùå Error generando imagen: {e}")
            continue

def crear_galeria(imagenes):
    """
    Crea una galer√≠a visual de las im√°genes generadas
    """
    if not imagenes:
        print("‚ö†Ô∏è  No hay im√°genes para mostrar")
        return
    
    print(f"\nüñºÔ∏è  Creando galer√≠a de {len(imagenes)} im√°genes...")
    
    # Calcular dimensiones de la grilla
    n_imagenes = len(imagenes)
    cols = min(3, n_imagenes)
    rows = (n_imagenes + cols - 1) // cols
    
    # Crear figura
    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))
    if n_imagenes == 1:
        axes = [axes]
    elif rows == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    
    for i, img_data in enumerate(imagenes):
        if i < len(axes):
            axes[i].imshow(img_data["imagen"])
            axes[i].set_title(f"Prompt: {img_data['prompt'][:30]}...", fontsize=10)
            axes[i].axis('off')
    
    # Ocultar ejes sobrantes
    for i in range(len(imagenes), len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    
    # Guardar galer√≠a
    directorio_salida = crear_directorio_salida()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ruta_galeria = os.path.join(directorio_salida, f"galeria_{timestamp}.png")
    plt.savefig(ruta_galeria, dpi=300, bbox_inches='tight')
    
    print(f"üì∏ Galer√≠a guardada como: {ruta_galeria}")
    
    # Mostrar galer√≠a
    try:
        plt.show()
    except Exception:
        print("‚ö†Ô∏è  No se pudo mostrar la galer√≠a autom√°ticamente")

def main():
    """
    Funci√≥n principal que ejecuta todos los ejemplos
    """
    print("ü§ó GENERACI√ìN DE IM√ÅGENES CON HUGGING FACE")
    print("=" * 60)
    print("Este script demuestra c√≥mo generar im√°genes usando Stable Diffusion")
    
    # Verificar dependencias
    try:
        import diffusers
        print(f"‚úÖ Diffusers versi√≥n: {diffusers.__version__}")
    except ImportError:
        print("‚ùå Error: diffusers no est√° instalado")
        print("üí° Instala con: pip install diffusers")
        return
    
    print(f"‚úÖ PyTorch versi√≥n: {torch.__version__}")
    print(f"‚úÖ CUDA disponible: {'S√≠' if torch.cuda.is_available() else 'No'}")
    
    try:
        # 1. Generaci√≥n b√°sica
        print("\n" + "="*60)
        print("1Ô∏è‚É£  GENERACI√ìN B√ÅSICA")
        print("="*60)
        imagenes_generadas = generar_imagen_basica()
        
        if imagenes_generadas:
            # 2. Crear galer√≠a
            print("\n" + "="*60)
            print("2Ô∏è‚É£  CREANDO GALER√çA")
            print("="*60)
            crear_galeria(imagenes_generadas)
        
        # 3. Generaci√≥n personalizada (opcional)
        print("\n" + "="*60)
        print("3Ô∏è‚É£  GENERACI√ìN PERSONALIZADA")
        print("="*60)
        
        continuar = input("¬øQuieres probar la generaci√≥n personalizada? (s/n): ").lower()
        if continuar in ['s', 'si', 's√≠', 'y', 'yes']:
            generar_imagen_personalizada()
        
        print("\nüéâ ¬°Generaci√≥n de im√°genes completada!")
        print("üí° Consejos:")
        print("   ‚Ä¢ Las im√°genes se guardan en el directorio 'imagenes_generadas'")
        print("   ‚Ä¢ Usa prompts en ingl√©s para mejores resultados")
        print("   ‚Ä¢ Experimenta con diferentes estilos y par√°metros")
        print("   ‚Ä¢ Para mejor calidad, usa m√°s pasos de inferencia (50-100)")
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Generaci√≥n cancelada por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante la ejecuci√≥n: {e}")
        print("üí° Verifica que todas las dependencias est√©n instaladas:")
        print("   pip install diffusers transformers accelerate")

if __name__ == "__main__":
    main()
