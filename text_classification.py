#!/usr/bin/env python3
"""
Ejemplo de Clasificaci√≥n de Texto con Hugging Face
==================================================

Este script demuestra diferentes t√©cnicas de clasificaci√≥n de texto
usando modelos preentrenados y fine-tuning con Hugging Face.
"""

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
from datasets import Dataset, load_dataset
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

def clasificacion_basica_zero_shot():
    """
    Ejemplo de clasificaci√≥n zero-shot (sin entrenamiento previo)
    """
    print("üöÄ Clasificaci√≥n Zero-Shot...")
    
    # Crear pipeline de clasificaci√≥n zero-shot
    classifier = pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli",
        device=0 if torch.cuda.is_available() else -1
    )
    
    # Textos de ejemplo
    textos = [
        "Me encanta programar en Python, es muy divertido",
        "El partido de f√∫tbol fue emocionante hasta el final",
        "La nueva pel√≠cula de Marvel es incre√≠ble",
        "Necesito comprar ingredientes para hacer una pizza",
        "El mercado de valores subi√≥ significativamente hoy",
        "Mi gato se perdi√≥ y estoy muy preocupado",
        "La conferencia sobre inteligencia artificial fue muy educativa"
    ]
    
    # Categor√≠as candidatas
    categorias = [
        "tecnolog√≠a", "deportes", "entretenimiento", 
        "cocina", "finanzas", "mascotas", "educaci√≥n"
    ]
    
    print("\nüìù Clasificando textos en categor√≠as:")
    print(f"Categor√≠as: {', '.join(categorias)}")
    print("-" * 70)
    
    resultados = []
    
    for i, texto in enumerate(textos, 1):
        resultado = classifier(texto, categorias)
        
        categoria_principal = resultado['labels'][0]
        confianza_principal = resultado['scores'][0] * 100
        
        print(f"{i}. Texto: {texto}")
        print(f"   Categor√≠a: {categoria_principal} ({confianza_principal:.1f}%)")
        
        # Mostrar top 3 categor√≠as
        print("   Top 3 categor√≠as:")
        for j in range(min(3, len(resultado['labels']))):
            cat = resultado['labels'][j]
            conf = resultado['scores'][j] * 100
            print(f"      {j+1}. {cat}: {conf:.1f}%")
        print()
        
        resultados.append({
            'texto': texto,
            'categoria': categoria_principal,
            'confianza': confianza_principal,
            'todas_categorias': resultado['labels'],
            'todas_confianzas': resultado['scores']
        })
    
    return resultados

def clasificacion_emociones():
    """
    Ejemplo espec√≠fico de clasificaci√≥n de emociones
    """
    print("üòä Clasificaci√≥n de Emociones...")
    
    # Pipeline especializado en emociones
    emotion_classifier = pipeline(
        "text-classification",
        model="j-hartmann/emotion-english-distilroberta-base",
        device=0 if torch.cuda.is_available() else -1
    )
    
    # Textos con diferentes emociones
    textos_emocionales = [
        "I'm so excited about my vacation next week!",
        "I can't believe they cancelled the concert, I'm devastated.",
        "This traffic is making me so angry and frustrated.",
        "I feel anxious about the job interview tomorrow.",
        "Spending time with my family makes me feel so happy and grateful.",
        "I'm really surprised by how well the project turned out.",
        "I feel disgusted by the way they treated the animals."
    ]
    
    print("\nüé≠ Analizando emociones en textos:")
    print("-" * 60)
    
    emociones_detectadas = []
    
    for i, texto in enumerate(textos_emocionales, 1):
        resultado = emotion_classifier(texto)
        
        # Obtener todas las emociones con sus scores
        emociones = [(r['label'], r['score']) for r in resultado]
        emocion_principal = emociones[0]
        
        print(f"{i}. Texto: {texto}")
        print(f"   Emoci√≥n principal: {emocion_principal[0]} ({emocion_principal[1]*100:.1f}%)")
        
        # Mostrar todas las emociones si hay m√∫ltiples
        if len(emociones) > 1:
            print("   Otras emociones detectadas:")
            for emocion, score in emociones[1:3]:  # Top 3
                print(f"      ‚Ä¢ {emocion}: {score*100:.1f}%")
        print()
        
        emociones_detectadas.append({
            'texto': texto,
            'emocion': emocion_principal[0],
            'confianza': emocion_principal[1] * 100,
            'todas_emociones': emociones
        })
    
    return emociones_detectadas

def clasificacion_idioma():
    """
    Ejemplo de detecci√≥n de idioma
    """
    print("üåç Detecci√≥n de Idioma...")
    
    # Textos en diferentes idiomas
    textos_multiidioma = [
        "Hello, how are you today?",
        "Hola, ¬øc√≥mo est√°s hoy?",
        "Bonjour, comment allez-vous aujourd'hui?",
        "Guten Tag, wie geht es Ihnen heute?",
        "Ciao, come stai oggi?",
        "„Åì„Çì„Å´„Å°„ÅØ„ÄÅ‰ªäÊó•„ÅØ„ÅÑ„Åã„Åå„Åß„Åô„ÅãÔºü",
        "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞ —Å–µ–≥–æ–¥–Ω—è?",
        "‰Ω†Â•ΩÔºå‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü"
    ]
    
    # Usar pipeline de clasificaci√≥n con modelo de detecci√≥n de idioma
    language_detector = pipeline(
        "text-classification",
        model="papluca/xlm-roberta-base-language-detection",
        device=0 if torch.cuda.is_available() else -1
    )
    
    print("\nüîç Detectando idiomas:")
    print("-" * 50)
    
    # Mapeo de c√≥digos de idioma a nombres
    idiomas = {
        'en': 'Ingl√©s', 'es': 'Espa√±ol', 'fr': 'Franc√©s', 'de': 'Alem√°n',
        'it': 'Italiano', 'ja': 'Japon√©s', 'ru': 'Ruso', 'zh': 'Chino',
        'pt': 'Portugu√©s', 'ar': '√Årabe', 'hi': 'Hindi', 'ko': 'Coreano'
    }
    
    for i, texto in enumerate(textos_multiidioma, 1):
        resultado = language_detector(texto)
        
        codigo_idioma = resultado[0]['label']
        confianza = resultado[0]['score'] * 100
        nombre_idioma = idiomas.get(codigo_idioma, codigo_idioma)
        
        print(f"{i}. '{texto}'")
        print(f"   ‚Üí {nombre_idioma} ({codigo_idioma}) - {confianza:.1f}%")
        print()

def clasificacion_personalizada_con_datos():
    """
    Ejemplo de clasificaci√≥n con datos personalizados
    """
    print("üéØ Clasificaci√≥n con Datos Personalizados...")
    
    # Crear dataset de ejemplo para clasificaci√≥n de reviews
    datos_ejemplo = [
        # Reviews positivos
        ("Este producto es fant√°stico, lo recomiendo totalmente", "positivo"),
        ("Excelente calidad, super√≥ mis expectativas", "positivo"),
        ("Me encanta, definitivamente volver√© a comprar", "positivo"),
        ("Muy buena experiencia de compra, r√°pido y eficiente", "positivo"),
        ("Producto de alta calidad, vale la pena el precio", "positivo"),
        
        # Reviews negativos
        ("Terrible producto, no funciona como se describe", "negativo"),
        ("Muy decepcionante, perd√≠ mi dinero", "negativo"),
        ("P√©sima calidad, se rompi√≥ al primer uso", "negativo"),
        ("No lo recomiendo para nada, muy malo", "negativo"),
        ("Servicio al cliente horrible, nunca m√°s compro aqu√≠", "negativo"),
        
        # Reviews neutros
        ("El producto est√° bien, nada especial", "neutral"),
        ("Cumple su funci√≥n b√°sica, precio justo", "neutral"),
        ("No est√° mal pero tampoco es extraordinario", "neutral"),
        ("Producto promedio, hay mejores opciones", "neutral"),
        ("Funciona correctamente, sin m√°s", "neutral")
    ]
    
    # Separar textos y etiquetas
    textos = [dato[0] for dato in datos_ejemplo]
    etiquetas = [dato[1] for dato in datos_ejemplo]
    
    print(f"\nüìä Dataset de ejemplo creado:")
    print(f"   Total de muestras: {len(datos_ejemplo)}")
    
    # Contar etiquetas
    from collections import Counter
    conteo_etiquetas = Counter(etiquetas)
    for etiqueta, cantidad in conteo_etiquetas.items():
        print(f"   {etiqueta}: {cantidad} muestras")
    
    # Usar modelo preentrenado para clasificar estos textos
    classifier = pipeline(
        "sentiment-analysis",
        model="nlptown/bert-base-multilingual-uncased-sentiment",
        device=0 if torch.cuda.is_available() else -1
    )
    
    print("\nüî¨ Clasificando con modelo preentrenado:")
    print("-" * 60)
    
    predicciones = []
    etiquetas_reales = []
    
    for texto, etiqueta_real in datos_ejemplo:
        resultado = classifier(texto)
        prediccion = resultado[0]
        
        # Mapear etiquetas del modelo a nuestras etiquetas
        mapeo_etiquetas = {
            'LABEL_1': 'muy_negativo', 'LABEL_2': 'negativo', 'LABEL_3': 'neutral',
            'LABEL_4': 'positivo', 'LABEL_5': 'muy_positivo',
            'NEGATIVE': 'negativo', 'POSITIVE': 'positivo'
        }
        
        etiqueta_predicha = mapeo_etiquetas.get(prediccion['label'], prediccion['label'])
        confianza = prediccion['score'] * 100
        
        print(f"Texto: {texto[:50]}...")
        print(f"Real: {etiqueta_real} | Predicho: {etiqueta_predicha} ({confianza:.1f}%)")
        print()
        
        predicciones.append(etiqueta_predicha)
        etiquetas_reales.append(etiqueta_real)
    
    return predicciones, etiquetas_reales

def visualizar_resultados_clasificacion(resultados):
    """
    Crear visualizaciones de los resultados de clasificaci√≥n
    """
    print("üìà Creando visualizaciones...")
    
    # Preparar datos
    df = pd.DataFrame(resultados)
    
    # Configurar estilo
    plt.style.use('seaborn-v0_8')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Distribuci√≥n de categor√≠as
    categoria_counts = df['categoria'].value_counts()
    colors = plt.cm.Set3(np.linspace(0, 1, len(categoria_counts)))
    
    wedges, texts, autotexts = ax1.pie(categoria_counts.values, 
                                      labels=categoria_counts.index,
                                      autopct='%1.1f%%',
                                      colors=colors,
                                      startangle=90)
    ax1.set_title('Distribuci√≥n de Categor√≠as', fontsize=14, fontweight='bold')
    
    # 2. Confianza promedio por categor√≠a
    confianza_por_categoria = df.groupby('categoria')['confianza'].mean().sort_values(ascending=True)
    
    bars = ax2.barh(confianza_por_categoria.index, confianza_por_categoria.values)
    ax2.set_xlabel('Confianza Promedio (%)')
    ax2.set_title('Confianza Promedio por Categor√≠a', fontsize=14, fontweight='bold')
    ax2.grid(axis='x', alpha=0.3)
    
    # A√±adir valores en las barras
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax2.text(width + 1, bar.get_y() + bar.get_height()/2, 
                f'{width:.1f}%', ha='left', va='center', fontweight='bold')
    
    # 3. Distribuci√≥n de confianza
    ax3.hist(df['confianza'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')
    ax3.set_xlabel('Nivel de Confianza (%)')
    ax3.set_ylabel('Frecuencia')
    ax3.set_title('Distribuci√≥n de Niveles de Confianza', fontsize=14, fontweight='bold')
    ax3.grid(axis='y', alpha=0.3)
    
    # 4. Scatter plot: longitud del texto vs confianza
    df['longitud_texto'] = df['texto'].str.len()
    scatter = ax4.scatter(df['longitud_texto'], df['confianza'], 
                         c=pd.Categorical(df['categoria']).codes, 
                         cmap='tab10', alpha=0.7, s=100)
    ax4.set_xlabel('Longitud del Texto (caracteres)')
    ax4.set_ylabel('Confianza (%)')
    ax4.set_title('Longitud del Texto vs Confianza', fontsize=14, fontweight='bold')
    ax4.grid(alpha=0.3)
    
    # A√±adir leyenda para el scatter plot
    categorias_unicas = df['categoria'].unique()
    handles = [plt.Line2D([0], [0], marker='o', color='w', 
                         markerfacecolor=plt.cm.tab10(i), markersize=8, label=cat)
              for i, cat in enumerate(categorias_unicas)]
    ax4.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig('classification_results.png', dpi=300, bbox_inches='tight')
    print("üíæ Gr√°fico guardado como 'classification_results.png'")
    plt.show()

def ejemplo_interactivo_clasificacion():
    """
    Modo interactivo para clasificaci√≥n personalizada
    """
    print("\nüéÆ Modo Interactivo - Clasificaci√≥n de Texto")
    print("Clasifica tus propios textos en categor√≠as personalizadas")
    print("Escribe 'salir' para terminar")
    print("-" * 60)
    
    # Configurar categor√≠as personalizadas
    print("üìã Primero, define las categor√≠as para clasificar:")
    categorias_input = input("Ingresa categor√≠as separadas por comas: ").strip()
    
    if not categorias_input:
        categorias = ["positivo", "negativo", "neutral"]
        print(f"Usando categor√≠as por defecto: {categorias}")
    else:
        categorias = [cat.strip() for cat in categorias_input.split(',')]
        print(f"Categor√≠as definidas: {categorias}")
    
    # Inicializar clasificador
    classifier = pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli",
        device=0 if torch.cuda.is_available() else -1
    )
    
    print(f"\nüîÑ Clasificador listo con {len(categorias)} categor√≠as")
    print("Ahora ingresa textos para clasificar:")
    
    while True:
        texto = input("\nüìù Ingresa tu texto: ").strip()
        
        if texto.lower() in ['salir', 'exit', 'quit', '']:
            print("üëã ¬°Hasta luego!")
            break
        
        try:
            print("üîÑ Clasificando...")
            resultado = classifier(texto, categorias)
            
            print(f"\nüéØ Resultados para: '{texto}'")
            print("-" * 50)
            
            # Mostrar todas las categor√≠as con sus scores
            for i, (categoria, score) in enumerate(zip(resultado['labels'], resultado['scores'])):
                emoji = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else "üìä"
                print(f"{emoji} {categoria}: {score*100:.1f}%")
            
            # Barra visual para la categor√≠a principal
            score_principal = resultado['scores'][0] * 100
            barra_length = int(score_principal / 5)  # Escalar a 20 caracteres max
            barra = "‚ñà" * barra_length + "‚ñë" * (20 - barra_length)
            print(f"\nüìà Confianza: [{barra}] {score_principal:.1f}%")
            
        except Exception as e:
            print(f"‚ùå Error al clasificar: {e}")

def main():
    """
    Funci√≥n principal que ejecuta todos los ejemplos
    """
    print("ü§ó Ejemplos de Clasificaci√≥n de Texto con Hugging Face")
    print("=" * 70)
    
    try:
        # Clasificaci√≥n zero-shot
        print("1Ô∏è‚É£  Ejecutando clasificaci√≥n zero-shot...")
        resultados_zero_shot = clasificacion_basica_zero_shot()
        
        # Clasificaci√≥n de emociones
        print("\n2Ô∏è‚É£  Ejecutando clasificaci√≥n de emociones...")
        clasificacion_emociones()
        
        # Detecci√≥n de idioma
        print("\n3Ô∏è‚É£  Ejecutando detecci√≥n de idioma...")
        clasificacion_idioma()
        
        # Clasificaci√≥n con datos personalizados
        print("\n4Ô∏è‚É£  Ejecutando clasificaci√≥n personalizada...")
        clasificacion_personalizada_con_datos()
        
        # Visualizaciones
        print("\n5Ô∏è‚É£  Creando visualizaciones...")
        visualizar_resultados_clasificacion(resultados_zero_shot)
        
        # Modo interactivo
        respuesta = input("\n¬øQuieres probar el modo interactivo? (s/n): ").lower()
        if respuesta in ['s', 'si', 's√≠', 'yes', 'y']:
            ejemplo_interactivo_clasificacion()
        
        print("\n‚úÖ ¬°Ejemplos de clasificaci√≥n completados exitosamente!")
        
        # Consejos finales
        print("\nüí° Consejos para mejorar la clasificaci√≥n:")
        print("   ‚Ä¢ Zero-shot funciona bien para categor√≠as generales")
        print("   ‚Ä¢ Para dominios espec√≠ficos, considera fine-tuning")
        print("   ‚Ä¢ Usa modelos multiling√ºes para textos en espa√±ol")
        print("   ‚Ä¢ Combina m√∫ltiples modelos para mejor precisi√≥n")
        print("   ‚Ä¢ Eval√∫a siempre con datos de prueba representativos")
        
    except Exception as e:
        print(f"‚ùå Error durante la ejecuci√≥n: {e}")
        print("üí° Aseg√∫rate de haber instalado todas las dependencias con:")
        print("   pip install -r requirements.txt")

if __name__ == "__main__":
    main()
