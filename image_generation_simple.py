#!/usr/bin/env python3
"""
Ejemplo Simplificado de GeneraciÃ³n de ImÃ¡genes con Hugging Face
===============================================================

Este script demuestra cÃ³mo generar imÃ¡genes usando modelos de diffusion
de manera simple y robusta, evitando problemas de compatibilidad.
"""

import os
import warnings
from datetime import datetime

# Suprimir warnings
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

def verificar_dependencias():
    """
    Verifica que las dependencias necesarias estÃ©n instaladas
    """
    dependencias_faltantes = []
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
    except ImportError:
        dependencias_faltantes.append("torch")
    
    try:
        from PIL import Image
        print("âœ… PIL (Pillow): Disponible")
    except ImportError:
        dependencias_faltantes.append("pillow")
    
    try:
        import matplotlib.pyplot as plt
        print("âœ… Matplotlib: Disponible")
    except ImportError:
        dependencias_faltantes.append("matplotlib")
    
    try:
        # Intentar importar diffusers de manera segura
        from diffusers import StableDiffusionPipeline
        print("âœ… Diffusers: Disponible")
        return True, None
    except ImportError as e:
        print(f"âŒ Error con diffusers: {e}")
        dependencias_faltantes.append("diffusers")
    
    if dependencias_faltantes:
        print(f"\nâŒ Dependencias faltantes: {', '.join(dependencias_faltantes)}")
        print("ğŸ’¡ Instala con: pip install torch pillow matplotlib diffusers")
        return False, dependencias_faltantes
    
    return True, None

def crear_directorio_salida():
    """
    Crea el directorio para guardar las imÃ¡genes
    """
    directorio = "imagenes_generadas"
    if not os.path.exists(directorio):
        os.makedirs(directorio)
        print(f"ğŸ“ Directorio creado: {directorio}")
    return directorio

def generar_imagen_simple():
    """
    Genera una imagen usando un modelo simple y confiable
    """
    print("ğŸ¨ Generando imagen con Stable Diffusion...")
    print("-" * 60)
    
    try:
        import torch
        from diffusers import StableDiffusionPipeline
        from PIL import Image
        
        # Detectar dispositivo
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ–¥ï¸  Usando dispositivo: {device}")
        
        # Usar modelo mÃ¡s pequeÃ±o y confiable
        model_id = "runwayml/stable-diffusion-v1-5"
        
        print("ğŸ“¥ Cargando modelo (esto puede tomar unos minutos la primera vez)...")
        
        # ConfiguraciÃ³n mÃ¡s conservadora para evitar errores
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float32,  # Usar float32 para compatibilidad
            safety_checker=None,
            requires_safety_checker=False,
            use_safetensors=True
        )
        
        pipe = pipe.to(device)
        
        # Optimizaciones para CPU
        if device == "cpu":
            pipe.enable_attention_slicing()
            print("ğŸ”§ Optimizaciones para CPU habilitadas")
        
        print("âœ… Modelo cargado exitosamente!")
        
        # Directorio de salida
        directorio_salida = crear_directorio_salida()
        
        # Prompt simple de prueba
        prompt = "a beautiful landscape with mountains and a lake, digital art"
        print(f"\nğŸ­ Generando imagen con prompt: '{prompt}'")
        
        # Generar imagen con parÃ¡metros conservadores
        print("ğŸ”„ Generando... (esto puede tomar 1-2 minutos)")
        
        image = pipe(
            prompt,
            num_inference_steps=20,  # Pocos pasos para rapidez
            guidance_scale=7.5,
            width=512,
            height=512,
            num_images_per_prompt=1
        ).images[0]
        
        # Guardar imagen
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        nombre_archivo = f"imagen_test_{timestamp}.png"
        ruta_completa = os.path.join(directorio_salida, nombre_archivo)
        
        image.save(ruta_completa)
        print(f"âœ… Imagen guardada como: {ruta_completa}")
        
        # Mostrar informaciÃ³n de la imagen
        print(f"ğŸ“ Dimensiones: {image.size}")
        print(f"ğŸ¨ Formato: {image.format}")
        
        return ruta_completa, image
        
    except Exception as e:
        print(f"âŒ Error generando imagen: {e}")
        print("\nğŸ’¡ Posibles soluciones:")
        print("   1. Verifica que tengas suficiente memoria RAM (mÃ­nimo 4GB)")
        print("   2. Cierra otras aplicaciones que consuman memoria")
        print("   3. Si persiste, reinicia el script")
        return None, None

def modo_interactivo():
    """
    Permite al usuario generar imÃ¡genes con sus propios prompts
    """
    print("\nğŸ® MODO INTERACTIVO")
    print("=" * 60)
    print("Ingresa tus propios prompts para generar imÃ¡genes")
    print("Escribe 'salir' para terminar")
    print("\nğŸ’¡ Consejos para mejores resultados:")
    print("   â€¢ Usa descripciones especÃ­ficas en inglÃ©s")
    print("   â€¢ AÃ±ade estilos: 'digital art', 'oil painting', 'photorealistic'")
    print("   â€¢ Incluye detalles: 'highly detailed', 'beautiful lighting'")
    
    try:
        import torch
        from diffusers import StableDiffusionPipeline
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model_id = "runwayml/stable-diffusion-v1-5"
        
        print(f"\nğŸ“¥ Cargando modelo para modo interactivo...")
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float32,
            safety_checker=None,
            requires_safety_checker=False,
            use_safetensors=True
        )
        pipe = pipe.to(device)
        
        if device == "cpu":
            pipe.enable_attention_slicing()
        
        directorio_salida = crear_directorio_salida()
        contador = 1
        
        while True:
            print(f"\nğŸ¨ Imagen #{contador}")
            prompt = input("Ingresa tu prompt: ").strip()
            
            if prompt.lower() in ['salir', 'exit', 'quit']:
                print("ğŸ‘‹ Â¡Hasta luego!")
                break
            
            if not prompt:
                print("âš ï¸  Por favor ingresa un prompt vÃ¡lido")
                continue
            
            print(f"ğŸ”„ Generando imagen para: '{prompt}'...")
            
            try:
                image = pipe(
                    prompt,
                    num_inference_steps=20,
                    guidance_scale=7.5,
                    width=512,
                    height=512
                ).images[0]
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                nombre_archivo = f"custom_{contador}_{timestamp}.png"
                ruta_archivo = os.path.join(directorio_salida, nombre_archivo)
                
                image.save(ruta_archivo)
                print(f"âœ… Imagen guardada: {ruta_archivo}")
                
                contador += 1
                
            except Exception as e:
                print(f"âŒ Error: {e}")
                continue
    
    except Exception as e:
        print(f"âŒ Error en modo interactivo: {e}")

def main():
    """
    FunciÃ³n principal
    """
    print("ğŸ¤— GENERADOR DE IMÃGENES SIMPLE CON HUGGING FACE")
    print("=" * 60)
    print("VersiÃ³n simplificada para evitar problemas de compatibilidad")
    
    # Verificar dependencias
    dependencias_ok, faltantes = verificar_dependencias()
    if not dependencias_ok:
        return
    
    print(f"\nğŸš€ Iniciando generaciÃ³n de imÃ¡genes...")
    
    try:
        # 1. Generar imagen de prueba
        print("\n" + "="*60)
        print("1ï¸âƒ£  GENERACIÃ“N DE PRUEBA")
        print("="*60)
        
        ruta_imagen, imagen = generar_imagen_simple()
        
        if ruta_imagen:
            print(f"\nğŸ‰ Â¡Primera imagen generada exitosamente!")
            
            # 2. Preguntar si quiere modo interactivo
            continuar = input("\nÂ¿Quieres probar el modo interactivo? (s/n): ").lower()
            if continuar in ['s', 'si', 'sÃ­', 'y', 'yes']:
                modo_interactivo()
        else:
            print("\nâŒ No se pudo generar la imagen de prueba")
            print("ğŸ’¡ Revisa los errores anteriores")
    
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Proceso cancelado por el usuario")
    except Exception as e:
        print(f"\nâŒ Error inesperado: {e}")
        print("ğŸ’¡ Intenta reiniciar el script")
    
    print("\nğŸ“ Notas finales:")
    print("   â€¢ Las imÃ¡genes se guardan en 'imagenes_generadas/'")
    print("   â€¢ Usa prompts en inglÃ©s para mejores resultados")
    print("   â€¢ La primera ejecuciÃ³n es mÃ¡s lenta (descarga el modelo)")
    print("   â€¢ Necesitas al menos 4GB de RAM libre")

if __name__ == "__main__":
    main()
